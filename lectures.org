* 均值(mean)
** 算数平均值(arithmetic mean)
   #+BEGIN_SRC python :results output :exports both
     import numpy as np

     x1 = [1, 2, 2, 3, 4, 5, 5, 7]
     x2 = x1 + [100]

     print 'Mean of x1:', sum(x1), '/', len(x1), '=', np.mean(x1)
     print 'Mean of x2:', sum(x2), '/', len(x2), '=', np.mean(x2)
   #+END_SRC

   #+RESULTS:
   : Mean of x1: 29 / 8 = 3.625
   : Mean of x2: 129 / 9 = 14.3333333333
   
** 中位數(median)
   #+BEGIN_SRC python :results output :exports both
     import numpy as np

     x1 = [1, 2, 2, 3, 4, 5, 5, 7]
     x2 = x1 + [100]

     print 'Median of x1:', np.median(x1)
     print 'Median of x2:', np.median(x2)
   #+END_SRC

   #+RESULTS:
   : Median of x1: 3.5
   : Median of x2: 4.0

** 众数(mode)
   #+BEGIN_SRC python :results output :exports both
     def mode(array):
         most = max(list(map(array.count, array)))
         return list(set(filter(lambda x: array.count(x) == most, array)))
     x1 = [1, 2, 2, 3, 4, 5, 5, 7]
     print mode(x1)
   #+END_SRC

   #+RESULTS:
   : [2, 5]

** 几何平均数(geometric mean)
   #+BEGIN_SRC python :results output :exports both
     import scipy.stats as stats

     x1 = [1, 2, 2, 3, 4, 5, 5, 7]
     x2 = x1 + [100]

     print 'Geometric mean of x1:', stats.gmean(x1)
     print 'Geometric mean of x2:', stats.gmean(x2)
   #+END_SRC

   #+RESULTS:
   : Geometric mean of x1: 3.09410402498
   : Geometric mean of x2: 4.55253458762

** 调和平均数(harmonic mean)
   #+BEGIN_SRC python :results output :exports both
     import scipy.stats as stats

     x1 = [1, 2, 2, 3, 4, 5, 5, 7]
     x2 = x1 + [100]

     print 'Harmonic mean of x1:', stats.hmean(x1)
     print 'Harmonic mean of x2:', stats.hmean(x2)
   #+END_SRC

   #+RESULTS:
   : Harmonic mean of x1: 2.55902513328
   : Harmonic mean of x2: 2.86972365624

* 方差(variance)
* 线性回归 
** 使用条件
   - 变量不是随机的
     - The independent variable is not random
   - 误差项的方差保持稳定
     - The variance of the error term is constant across observations. This is important for evaluating the goodness of the fit.
   - 误差没有自相关性 
     - The errors are not autocorrelated. The Durbin-Watson statistic reported by the regression detects this. If it is close to  2, there is no autocorrelation.
   - 误差是正太分布的
     - The errors are normally distributed. If this does not hold, we cannot use some of the statistics, such as the F-test
   - 对于多元线性回归, 各变量相互是独立的 
     - There is no exact linear relationship between the independent variables. Otherwise, it is impossible to solve for the coefficients  βi  uniquely, since the same linear equation can be expressed in multiple ways.
** 结果分析
*** 模型基本信息 
**** R-squared
     - 表示目标值的变化由模型解释的精确程度
       - the R2 value tells us the fraction of the total variation of  YY  that is explained by the model
     - 值为[0, 1], 越大越好
**** Adj. R-squared
     - 同R-squared
**** F-statistic: 联合假设检验(joint hypotheses test)
     - 确定从样本(sample)统计结果推论至总体时所犯错的概率
     - 此外也称方差比率检验、方差齐性检验

**** Log-Likelihood
**** AIC: 赤池信息量(akaike information criterion)
     - 用于判断拟合优度的统计参数, 值越小越好 
**** BIC: 贝叶斯信息量(bayesian information criterion)
     - 类似AIC
*** 残差分析
**** Omnibus
**** Skew: 偏度
**** Kurtosis: 峰度
**** 杜宾-瓦特森统计量(Durbin-Watson statistic) [[[https://zh.wikipedia.org/wiki/%25E6%259D%259C%25E5%25AE%25BE-%25E7%2593%25A6%25E7%2589%25B9%25E6%25A3%25AE%25E7%25BB%259F%25E8%25AE%25A1%25E9%2587%258F][参考]]]
     - 用来检测回归分析中的残差项是否存在自相关
     - 数值如果接近2没有自相关性
**** Jarque-Bera
**** Cond. No.
*** 变量无相关建模
    #+BEGIN_SRC ipython :session :results output :exports both
      from pandas import Series
      from pandas import DataFrame
      from random import gauss
      from statsmodels import regression
      # 构造数据
      s = Series(range(1000))
      x1 = s.apply(lambda x: gauss(1, 1)).cumsum()
      x2 = s.apply(lambda x: gauss(1, 1)).cumsum()
      x3 = s.apply(lambda x: gauss(1, 1)).cumsum()
      x4 = s.apply(lambda x: gauss(1, 1)).cumsum()
      x5 = s.apply(lambda x: gauss(1, 1)).cumsum()
      Y = x1 + x3 * 2 + 5
      # 模型拟合
      X = DataFrame({'x1': x1, 'x2': x2, 'x3': x3, 'x4': x4, 'x5': x5})
      X['a'] = 1
      model = regression.linear_model.OLS(Y, X).fit()
      print list(model.params.round(3))
    #+END_SRC

    #+RESULTS:
    : [1.0, -0.0, 2.0, -0.0, -0.0, 5.0]
    

  



